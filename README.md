# TLM (TCP Language Model)

A small transformer-based language model that understands and generates TCP protocol sequences. TLM learns the patterns of TCP flags like SYN, ACK, FIN, RST, etc., and can generate realistic TCP connection flows.

## üöÄ Overview

TLM is a specialized language model designed to work with TCP protocol sequences instead of natural language. It understands the semantics of TCP flags and can generate valid TCP connection patterns, making it useful for:

- Network protocol education
- TCP sequence analysis
- Protocol simulation
- Network security research
- Automated network testing

## üèóÔ∏è Architecture

TLM consists of several key components:

### 1. TCP Tokenizer (`tcp_tokenizer.py`)
- Converts TCP flags into tokens for the model
- Supports individual flags: `SYN`, `ACK`, `FIN`, `RST`, `PSH`, `URG`, `ECE`, `CWR`, `NS`
- Handles flag combinations: `SYN-ACK`, `FIN-ACK`, `RST-ACK`, `PSH-ACK`
- Includes special tokens: `<START>`, `<END>`, `<PAD>`, `<UNK>`, `<SEP>`

### 2. Data Generator (`data_generator.py`)
- Generates realistic TCP connection sequences for training
- Supports multiple connection patterns:
  - Normal connections (3-way handshake + data + close)
  - Simple connections (basic handshake)
  - Data-heavy connections (multiple data transfers)
  - Reset connections (abrupt termination)
  - Failed connections (connection refused)
  - Urgent data connections

### 3. Transformer Model (`tlm_model.py`)
- Small but complete transformer architecture
- Multi-head self-attention mechanism
- Positional encoding for sequence understanding
- Causal masking for autoregressive generation
- Configurable model size (default: 128d model, 8 heads, 6 layers)

### 4. Training Pipeline (`train_tlm.py`)
- Complete training workflow
- Data generation and preprocessing
- Model training with validation
- Sequence quality analysis
- TCP protocol compliance checking

### 5. Interactive Demo (`demo_tlm.py`)
- User-friendly interface to interact with trained model
- Random sequence generation
- Sequence completion from partial inputs
- Batch generation and analysis
- Real-time TCP sequence validation

## üì¶ Installation

1. Clone or download the project files
2. Install dependencies:
```bash
pip install -r requirements.txt
```

## üéØ Quick Start

### Training a New Model
```bash
python train_tlm.py
```

This will:
- Generate training data with realistic TCP sequences
- Create and train the TLM model
- Save the trained model as `tlm_trained.pth`
- Evaluate the model's performance

### Running the Interactive Demo
```bash
python demo_tlm.py
```

The demo provides several options:
1. **Generate random sequences** - See what TLM creates from scratch
2. **Complete partial sequences** - Give TLM a start and see how it completes the connection
3. **Show vocabulary** - Explore the TCP tokens TLM understands
4. **Batch generation** - Generate multiple sequences for analysis

### Using Individual Components

#### Test the Tokenizer
```bash
python tcp_tokenizer.py
```

#### Generate Training Data
```bash
python data_generator.py
```

#### Test the Model
```bash
python tlm_model.py
```

## üîß Model Configuration

You can customize the model architecture by modifying parameters in `train_tlm.py`:

```python
model = TLMModel(
    vocab_size=tokenizer.vocab_size,  # Fixed by tokenizer
    d_model=128,                      # Embedding dimension
    n_heads=8,                        # Number of attention heads
    n_layers=6,                       # Number of transformer layers
    d_ff=512,                         # Feed-forward dimension
    max_len=50                        # Maximum sequence length
)
```

## üìä Example Outputs

### Generated TCP Sequences
```
SYN -> SYN-ACK -> ACK -> PSH-ACK -> FIN -> FIN-ACK
SYN -> SYN-ACK -> ACK -> PSH-ACK -> PSH-ACK -> FIN -> ACK
SYN -> RST-ACK
SYN -> SYN-ACK -> ACK -> URG -> PSH-ACK -> FIN -> FIN-ACK
```

### Sequence Completion
```
Input: SYN
Completion: SYN -> SYN-ACK -> ACK -> PSH-ACK -> FIN -> FIN-ACK

Input: SYN SYN-ACK
Completion: SYN -> SYN-ACK -> ACK -> PSH-ACK -> FIN -> ACK

Input: SYN SYN-ACK ACK
Completion: SYN -> SYN-ACK -> ACK -> PSH-ACK -> PSH-ACK -> FIN -> FIN-ACK
```

## üß† How It Works

1. **Tokenization**: TCP flags are converted to numerical tokens
2. **Training**: The model learns patterns from thousands of realistic TCP sequences
3. **Generation**: Given a prompt (or starting from scratch), the model predicts the next most likely TCP flag
4. **Validation**: Generated sequences are checked for TCP protocol compliance

## üìà Model Performance

The trained model typically achieves:
- **Sequence Validity**: 80-90% of generated sequences follow basic TCP rules
- **Protocol Compliance**: Correctly implements 3-way handshake patterns
- **Diversity**: Generates various connection types (normal, reset, data-heavy, etc.)
- **Completion Accuracy**: High accuracy in completing partial sequences

## üîç TCP Protocol Rules Implemented

TLM understands and follows these TCP protocol patterns:

1. **Connection Initiation**: Connections should start with `SYN`
2. **Three-way Handshake**: `SYN` ‚Üí `SYN-ACK` ‚Üí `ACK`
3. **Data Transfer**: `PSH-ACK` flags for data transmission
4. **Connection Termination**: Proper closing with `FIN` or `RST` flags
5. **Acknowledgments**: Appropriate `ACK` responses

## üõ†Ô∏è Customization

### Adding New TCP Flags
Modify `tcp_tokenizer.py` to add new flags:
```python
self.tcp_flags = [
    'SYN', 'ACK', 'FIN', 'RST', 'PSH', 'URG',
    'ECE', 'CWR', 'NS',
    'YOUR_NEW_FLAG'  # Add here
]
```

### Creating New Connection Patterns
Add patterns in `data_generator.py`:
```python
self.connection_patterns = {
    'your_pattern': [
        'SYN',
        'SYN-ACK',
        'ACK',
        # ... your sequence
    ]
}
```

## üìö Educational Use

TLM is excellent for learning TCP protocols:

- **Visual Learning**: See TCP sequences in action
- **Interactive Exploration**: Try different scenarios
- **Pattern Recognition**: Understand common TCP flows
- **Protocol Validation**: Learn what makes sequences valid

## ü§ù Contributing

Feel free to extend TLM with:
- Additional TCP flags or combinations
- More sophisticated connection patterns
- Enhanced validation rules
- Performance optimizations
- New evaluation metrics

## üìÑ License

This project is open source and available under the MIT License.

## üôè Acknowledgments

- Inspired by the TCP/IP protocol specification
- Built using PyTorch transformer architecture
- Designed for educational and research purposes

---

**TLM - Teaching machines the language of networks, one packet at a time! üåê**
